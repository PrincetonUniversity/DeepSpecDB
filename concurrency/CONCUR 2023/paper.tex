
\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2021}
%This is a template for producing LIPIcs articles. 
%See lipics-v2021-authors-guidelines.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for enabling a two-column layout for the author/affilation part (only applicable for > 6 authors), use "authorcolumns"
%for producing a PDF according the PDF/A standard, add "pdfa"

%\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the mandatory bibstyle
\usepackage{txfonts}
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
%% http://ctan.org/pkg/subcaption
\usepackage{uri}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathpartir}
\usepackage{semantic}
\usepackage{graphicx}
\usepackage{cases}
\usepackage{hyperref}
\usepackage{stmaryrd}
\usepackage{listings}
\usepackage{parcolumns}
\usepackage{iris}
%\usepackage{lstlangcoq}
\usepackage[edges]{forest}
\renewcommand{\lstlistingname}{Figure}

\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000

\lstset{language=C,basicstyle=\ttfamily,
	xleftmargin=\dimexpr\fboxsep-\fboxrule,
	mathescape=true,columns=fullflexible}

\newcommand{\TODO}[1]{\textbf{\textcolor{red}{[ TODO: #1]}}}
%\newcommand{\boxdotright}{\!\mathrel\boxdot\joinrel\rightarrow\!}
\newcommand{\islock}{\boxdotright}
\newcommand{\lockvar}{\islock}
\newcommand{\isaex}{\!\mathrel\odot\joinrel\rightarrow\!}
\newcommand{\xisaex}[1]{\!\mathrel\odot\joinrel\xrightarrow{#1}\!}
%% \newcommand{\ifthenelse}[3]{\text{if }#1\text{ then }#2\text{ else }#3}
\newcommand{\emp}{\mathsf{emp}}

\newcommand\dboxed[1]{\dbox{\ensuremath{#1}}}
\newcommand{\master}[2]{\ensuremath{\mathrm{Master}_{#1}(#2)}}
\newcommand{\snap}[1]{\ensuremath{\mathrm{Snapshot}(#1)}}
\newcommand{\ghost}[2]{\ensuremath{\dboxed{#1}^{#2}}}
\newcommand{\us}{$\mu$s}
\newcommand{\gnamety}{\ensuremath{\mathsf{gname}}}
\newcommand{\treerep}{\ensuremath{\mathsf{Node}}}
\newcommand{\nodeboxrep}{\ensuremath{\mathsf{Node\_ref}}}
\newcommand{\lockinv}{\ensuremath{\mathsf{lock\_inv}}}
\newcommand{\infp}{\ensuremath{\mathsf{InFP}}}

\newcommand{\myhalf}[2]{\ensuremath{\mathsf{my\_half}_{#1}(#2)}}
\newcommand{\publichalf}[1]{\ensuremath{\mathsf{public\_half}(#1)}}

% comments from authors 
\newcommand{\than}[1]{\textbf{\textcolor{blue}{[Than: #1]}}}
\newcommand{\lb}[1]{\textbf{\textcolor{red}{[Lennart: #1]}}}
\newcommand{\wm}[1]{\textbf{\textcolor{violet}{[William: #1]}}}
\newcommand{\ignore}[1]{}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{myStyle}{
	backgroundcolor=\color{white},   
	commentstyle=\color{codegreen},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	keepspaces=true,                 
	numbers=left,       
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=1,
}

\title{Compositional Verification of Concurrent C Programs with Search Structure Templates} %keep working on this

%\titlerunning{Dummy short title} %TODO optional, please use if title is longer than one line

\author{Duc Than Nguyen}{University of Illinois at Chicago, USA \and \url{http://dnguye96.people.uic.edu} }{dnguye96@uic.edu}{https://orcid.org/0000-0002-1825-0097}{(Optional) author-specific funding acknowledgements}%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional. Use additional curly braces to indicate the correct name splitting when the last name consists of multiple name parts.

\author{Lennart Beringer}{Princeton University, USA \and \url{https://www.cs.princeton.edu/~eberinge} }{eberinge@cs.princeton.edu}{https://orcid.org/0000-0002-1570-3492}{(Optional) author-specific funding acknowledgements}

\author{William Mansky}{University of Illinois at Chicago, USA\and \url{https://mansky.lab.uic.edu/} }{mansky1@uic.edu}{https://orcid.org/0000-0002-5351-895X}{(Optional) author-specific funding acknowledgements}

\author{Shengyi Wang}{Princeton University, USA \and \url{https://www.cs.princeton.edu/~shengyiw} }{shengyiw@cs.princeton.edu}{https://orcid.org/[0000-0002-2286-8703}{(Optional) author-specific funding acknowledgements}

\authorrunning{Duc Than Nguyen, Lennart Beringer,  William Mansky, and Shengyi Wang} %TODO mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'

\Copyright{Duc Than Nguyen and William Mansky} %TODO mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 

\keywords{concurrent separation logic, fine-grained locking, logical atomicity,
	Verified Software Toolchain, Iris} %TODO mandatory; please add comma-separated list of keywords

\category{} %optional, e.g. invited paper

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversiondetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93]{Classification (e.g. Full Version, Extended Version, Previous Version}{URL to related version} %linktext and cite are optional

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

\acknowledgements{I want to thank \dots}%optional

%\nolinenumbers %uncomment to disable line numbering



%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%don't say ``real'' so much
\begin{abstract}
%a bit more of a lead-in?
Concurrent search structure templates are a technique for separating the verification of a concurrent data structure into concurrency-control and data-structure components, which can then be modularly combined with no additional proof effort. In this paper, we implement the template approach in the Verified Software Toolchain (VST), and use it to prove correctness of C implementations of fine-grained concurrent data structures. This involves translating code, specifications, and proofs to the idiom of C and VST, and gives us another look at the requirements and limitations of the template approach.
We encounter several questions about the boundaries between template and data structure, as well as some common data structure operations that cannot naturally be decomposed into templates. Nonetheless, the approach appears promising for modular verification of real-world concurrent data structures.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
Krishna et al.~proposed concurrent search structure templates~\cite{templates} as a method for proving the correctness of concurrent data structures \emph{compositionally}, separating the proof of a concurrent access method (e.g., optimistic concurrency, hand-over-hand locking, forwarding via internal links) from the proof of the underlying data structure (e.g., linked list, hashtable, B-tree). The concurrency ``templates'' are verified parametrically over data structure operations, and the data structure operations are verified without any reference to concurrency. In theory, this could allow us to prove the correctness of $n$ (single-threaded) data structure implementations and $m$ concurrency patterns, and immediately obtain $n \times m$ verified concurrent data structures. In practice, the story is more complicated: certain patterns work only for specific data structures or require the data structures to store extra information, while some internal data structure operations may not fit the template model. %\wm{Maybe say more about the idea that they only built a proof of concept, and there are still important details not worked out/only tested on ad-hoc examples.}

%give a feel for the templates/the traverse function here, so people can understand why the reimplementation was hard/interesting
%mention separation logic, logical atomicity

The template approach was originally implemented on top of flow interfaces~\cite{krishna2017flow}, a framework for specifying and verifying graph-style data structures, in a combination of two verifiers: the templates were verified in the interactive Iris prover~\cite{iris}, while the data structure implementations were verified with the automated GRASShopper tool~\cite{grasshopper}. The target data structures were written in HeapLang, a simple functional programming language with shared-memory concurrency. In this paper, we reimplement the approach in the Verified Software Toolchain (VST)~\cite{plcc}, an interactive system for proving correctness of C programs based on a detailed semantics of the C language. This allows us to apply the template approach to concurrent data structure implementations in C. The template approach depends crucially on the idea of \emph{logically atomic specifications} introduced in TaDA~\cite{tada} and further developed in Iris~\cite{iris}. Our proofs make use of recent work integrating Iris-style logical atomicity into VST~\cite{iris-vst-arxiv}. %clean up the phrasing a little

Our specific contributions are:
\begin{itemize}
\item We reimplement the template approach without flow interfaces, with a simple interface involving only the concept of ``keys belonging in this node/subtree''.
\item We implement the template approach in VST, allowing us to apply it to C programs and obtain end-to-end correctness proofs in a single verification system.
\item To the best of our knowledge, this is the first mechanized verification of a template approach to concurrent data structure implementations in a real-world programming language, and its first application to data structures not written specifically as case studies.
\item We highlight several questions about the boundaries of the template/data structure division, and describe a limitation of the template approach on tree data structures.
\end{itemize}

\subsection*{Related Work}
CSL provers for fine-grained concurrent data structures: Iris~\cite{iris,iris-folly}, FCSL~\cite{fcsl}, TaDA~\cite{tada,Xiong2017Abstract}, VeriFast~\cite{verifast,verifast-conc}

%Gotsman et al.~\cite{gotsman}, in the same paper in which they introduced invariant-style lock specs, also verified a linked list with hand-over-hand locking, which became a common example for verifiers that handled fine-grained locking. VeriFast~\cite{verifast}, a separation-logic-based verifier for C and
%Java, supports lock-based and atomic
%concurrency~\cite{verifast-conc}, and has been used to verify a
%hand-over-hand-locking linked list similar to that of Krishna et al.
%The specifications of the lock operations and the list itself use
%a precursor of TaDA's logical atomicity. VeriFast is not 
%foundational, but its basic logic is verified
%against the semantics of a toy language in Coq.

%Xiong et al. \cite{Xiong2017Abstract} have demonstrated the verification of ConcurrentSkipListMap from java.util.concurrent library using the recent advances in fine-grained concurrency reasoning. Their work is mainly based on the abstract atomicity from TaDA logic, and give two modular specifications for concurrent maps: one specification focus on the entire map structure which is suitable for verifying implementation, and another specification focus on the key-value pairs which appropriate for verifying clients. We use the same idea of atomicity (though implemented in Iris) in our work. 

separating concurrency from functionality: linearizability~\cite{linearizability} (and refinement, e.g. Civl~\cite{civl}), logical atomicity~\cite{tada}

Proving highly-concurrent traversals correct \cite{feldman2020proving}

multicopy search structures~\cite{template-multi}

\section{Background}
\subsection{Concurrent Search Structure Templates}

A search structure is a data structure designed to efficiently store and retrieve data based on specific search criteria. In the abstract, a search structure implements a map from keys to values, and provides operations such as search, insertion, deletion, and traversal on that map. For efficiency, many such structures are designed to allow concurrent access and modification, often employing fine-grained or lock-free concurrency to allow as many threads as possible to operate on separate parts of the data structure. Designing these search structures presents significant challenges, including ensuring correctness and consistency under concurrent access, achieving scalability by minimizing contention and maximizing parallelism, and maintaining performance and efficiency while managing synchronization and memory, including cache behavior~\cite{masstree}. The complex interplay between concurrency and data structure design in concurrent search structures makes them challenging targets for formal verification.

The Concurrent Search Structure Template approach of Krishna et al.~\cite{templates} aims to make the problem tractable by separating verification of concurrency control patterns from verification of the underlying data structure. Addressing the proof of each component separately makes the individual proofs easier, and also offers the possibility of proof reuse: each verified concurrency pattern (``template'') can be applied to many different data structures, and each verified sequential data structure can be outfitted with many different templates. In theory, verifying $n$ templates and $m$ data structures might yield $n \times m$ verified concurrent data structures; in practice, as we will see, both templates and data structures make assumptions that may invalidate certain combinations. %how much more can we say about this?

We will discuss several templates in section~\ref{templates}, but broadly, a search structure template consists of a \lstinline{traverse} function that travels through a data structure in search of a particular key, using the appropriate concurrency control mechanism when moving from node to node. The node to travel to is selected by a black-box function \lstinline{findNext} provided by the data structure; all the template needs to know is that it has some way of choosing a next node to examine when the current node does not contain the target key. \wm{Show an example template here, and enough of the specification to explain atomicity -- one findNext, one traverse, one top-level insert -- see fig 3 in template paper} Once the appropriate node for the key has been found, the template returns it to a top-level function that calls out to the data structure to perform the appropriate operation (e.g. insert, lookup, delete) on that node. Thus, the \lstinline{traverse} function can be verified without knowing anything about the target data structure other than its synchronization mechanism, and without knowing anything about the operation to be performed other than that it can be performed on a single node (or sometimes a node and its parent). The job of the data structure is to implement the \lstinline{findNext} function and the specific operations; the combination of the template and the data structure is then a fully operational concurrent data structure. Krishna et al.~presented templates in terms of \emph{flow interfaces}~\cite{krishna2017flow}, a framework for reasoning about graph-structured data structures, but many common search structures are not graphs; in this paper, we present a version of templates that is independent of flow interfaces. %is this a contribution in itself?
%what more do we want to say here?

\subsubsection{Logical atomicity} 
%In this section, we show how to verify the templates presented above, by proving that each \lstinline{traverse} function meets its specification. %The detailed exploration of these template verifications will be discussed in Section \ref{traverse_proof_lock} and \ref{traverse_proof_giveup}.

%But first, we need to understand how to specify the correctness of \lstinline{traverse} independently of the data structure operations (insert, lookup, etc.) it will be used to implement. The key is the concept of \emph{logical atomicity}~\cite{tada}, a highly compositional approach to specifying concurrent data structure operations. \wm{Should this go in background instead?}

Logical atomicity is a concurrent separation logic (CSL) technique for concisely specifying the behavior of a concurrent operation. A logically atomic triple has the form $\forall a.\ \left\langle \texttt{P}_l\ |\ \texttt{P}_p(a) \right\rangle\ \texttt{c}\ \left\langle \texttt{Q}_l\ |\ \texttt{Q}_p(a)\right\rangle$, where $\texttt{P}_l$ and $\texttt{Q}_l$ are \emph{local} preconditions and postconditions, akin to a standard Hoare triple, while $\texttt{P}_p$ and $\texttt{Q}_p$ are \emph{public} preconditions and postconditions, parameterized by an abstract value $a$ of the shared data structure. Intuitively, this says that \lstinline{c} is an operation on an abstract object (i.e., data structure) $a$, and its effect is to \emph{atomically} transform $a$ from a state satisfying $\texttt{P}_p$ to a state satisfying $\texttt{Q}_p$, with no intermediate states visible to any other thread. More precisely, the triple asserts that if $\texttt{P}_l$ holds true before a call to \lstinline{c} and $\texttt{P}_p$ is true for some value of $a$ in a shared state, then $\texttt{P}_p$ will continue to be true for some (possibly different) value of $a$ until the \emph{linearization point} of $\texttt{c}$, at which point $\texttt{Q}_p$ will become true atomically for the same value $a$ (and $\texttt{Q}_l$ will be true after $\texttt{c}$ ends). For instance, the specification
$\forall s.\ \left\langle \texttt{is\_stack}_g\ p\ |\ \texttt{stack}_g\ s\right\rangle\ \texttt{push}(v)\ \left\langle \texttt{is\_stack}_g\ p\ |\ \texttt{stack}_g\ (v::s)\right\rangle$
expresses the fact that the \lstinline{push} operation of a concurrent stack correctly implements the behavior of a sequential push, atomically transforming the stack from $s$ to $v::s$ at some point during its execution. The stack itself is a shared resource, and can only be accessed and modified atomically by threads holding the corresponding \texttt{is\_stack} assertion. The local and shared assertions are connected by an arbitrary identifier $g$, which we will generally omit when clear from context.

%To demonstrate the proof of an implementation that meets the atomic specification, let's take the example of the stack specification mentioned above. This specification assert that the implementation \texttt{push} appears to execute atomically, accessing and updating the state of the data structure without exposing any intermediate states. The local preconditions and postconditions, \texttt{is\_stack}, contain the points-to and lock-invariant assertions necessary for a thread, while the public preconditions and postconditions, \texttt{stack}, involve the ghost state that defines the overall state of the stack. Ghost state is a type of program state that aids in the verification process without affecting the program's runtime behavior, and by referring to an arbitrary ghost state identifier $g$ (which we will generally omit), it is possible to connect local and public conditions. To show that the implementation of \texttt{push}(v) satisfies these atomic specifications, two things must be demonstrated. Firstly, the implementation can execute safely without owning any piece of public assertion $\texttt{stack}$, only accessing it automatically and restoring it up until the linearization point. Secondly, at some linearization point, the implementation transforms the current stack $s$ into $v::s$ atomically, which satisfies the public postcondition $\texttt{stack}(v::s)$. 

Logical atomicity is key to the template approach: each template's \lstinline{traverse} function is proved to satisfy a logically atomic specification that says roughly ``this function finds the node where key \lstinline{k} belongs''. The traverse specifications can then be used to prove atomic specifications for the individual data structure operations, lifting the sequential specifications for insert, lookup, etc. to the concurrent setting.

\subsection{Iris and VST}
The search structure template approach uses \emph{concurrent separation logic} to specify and prove pre- and postconditions for the template and data structure functions. Krishna et al.~implemented their framework in Iris~\cite{iris}, a language-independent separation logic framework built in the Coq proof assistant~\cite{coq}, with flexible support for ghost state, invariants, and atomic specifications. This makes it easy to describe the effects of concurrency control functions independently of the underlying data structure, e.g., as ``this function atomically finds a node that contains the target key.'' %forward reference to where we show the specs? or show them here?
The existing implementation is written in Iris's HeapLang, a simple functional programming language with shared-memory concurrency.

To apply the template approach to real-world code, we instead use the Verified Software Toolchain (VST)~\cite{plcc}, a separation-logic-based verifier for C programs. VST is also built in Coq and is connected to the CompCert verified C compiler~\cite{compcert}, allowing it to guarantee that proved properties will hold on compiled code. Recent work on VST~\cite{iris-vst-arxiv} extended it to support most of the advanced concurrency features of Iris, including ghost state, invariants, and atomic specifications. In this paper, we use these extensions to reconstruct the template approach in VST and apply it to real C programs. %clean this up a little

\section{Search Structure Templates in VST}

\subsection{Defining the Templates}
\label{templates}

The core of each search structure template is a \lstinline{traverse} function that navigates a data structure using the target synchronization mechanism. \wm{\lstinline{traverse} is the core, but it's not the whole template! The data structure never sees traverse, but rather a wrapper around it that also acquires locks, etc. as necessary.} Templates abstract away from the data structure being traversed, operating on a generic \lstinline{node} type and taking data-structure-specific functions like \lstinline{findNext} (which chooses the next node to search) as parameters. We consider lock-based synchronization in this paper, and so our generic node type can be defined in C as:
\begin{lstlisting}[language = C, backgroundcolor=\color{white}, basicstyle=\ttfamily\footnotesize]
typedef struct node_t {node *t; lock_t *lock;} node_t;
\end{lstlisting}
There are two things worth noting about this data structure. First, each node has its own lock: all of our templates will use \emph{fine-grained locking}, holding as few locks as possible to allow other parts of the data structure to be modified concurrently. Second, the \lstinline{node} struct itself is defined by the target data structure: for instance, a binary search tree might define it as 
\begin{lstlisting}[language = C, backgroundcolor=\color{white}, basicstyle=\ttfamily\footnotesize]
typedef struct node {int key; void *value; struct node_t *left, *right;} node;
\end{lstlisting}
while a linked list might use
\begin{lstlisting}[language = C, backgroundcolor=\color{white}, basicstyle=\ttfamily\footnotesize]
typedef struct node {int key; void *value; struct node_t *next;} node;
\end{lstlisting}
This is the first place where we decompose our program into a generic concurrent component and a sequential data-structure component. Now, we use \lstinline{node_t} to define \lstinline{traverse} functions for specific concurrency patterns.

\subsection{Lock-Coupling Template}
\label{lock-coupling-algo}

The first template we consider is lock coupling (also called hand-over-hand locking), in which threads use the locks on each node to prevent interference from other threads during traversal. Each thread always holds at least one lock, and acquires the lock on the next node before releasing its current lock, ensuring that other threads cannot invalidate the ongoing search.
Figure \ref{traverse_lock} shows the lock-coupling \lstinline{traverse} function as presented by Krishna et al.~(Figure \ref{traverse_lock_a}) and our corresponding C implementation (Figure \ref{traverse_lock_b}). The C implementation uses a struct
\begin{lstlisting}[language = C, backgroundcolor=\color{white}, basicstyle=\ttfamily\footnotesize]
typedef struct pn {struct node_t *p; struct node_t *n;} pn;
\end{lstlisting}
to mimic the pair of nodes \lstinline{(p, n)} returned by the functional implementation, where \lstinline{n} is the current node and \lstinline{p} is its parent. The template relies on one function provided by the underlying data structure, namely \lstinline{findNext}, which is used to determine the next node $\texttt{n'}$ to be visited based on the current node $\texttt{n}$ and the key $\texttt{k}$. In the functional version, \lstinline{findNext} returns an \lstinline{option node}; in C, it instead returns a boolean and, if a next node is found, modifies \lstinline{pn->n}.

%To ensure thread safety, it is essential to acquire and release locks in a specific order during traversal. The lock-coupling scheme achieves this by requiring threads to acquire locks in increasing order of node addresses. The thread then releases the lock for the previous node before acquiring the lock for the next node in the traversal sequence. This guarantees that the locks are acquired and released in the same order across all threads and prevents deadlocks from occurring.

\begin{figure}[h]
	\begin{subfigure}[t]{0.45\textwidth}
		\lstinputlisting[language=caml, style=myStyle]{lock_traverse.ml} 
		\caption{The \lstinline{traverse} method of the lock-coupling template algorithm written in an ML-like language \cite{krishna2019compositional}} 
		\label{traverse_lock_a}	
	\end{subfigure}\qquad
	\begin{subfigure}[t]{0.48\textwidth}
		\lstinputlisting[language=C, style=myStyle]{lock_traverse.c} 
		\caption{The \lstinline{traverse} method of the lock-coupling template algorithm written in C}
		\label{traverse_lock_b}
	\end{subfigure}
	\caption{The \lstinline{traverse} method of the lock-coupling template algorithms}
	\label{traverse_lock}
\end{figure}

Our implementation of \lstinline{traverse} translates the functional implementation into more idiomatic C code. The lock-coupling pattern can be seen on lines 14 and 15, where \lstinline{traverse} acquires the next node's lock and then releases the current node's lock. The function stops when it reaches an empty leaf node (\lstinline{pn->p->t = NULL}), or when \lstinline{findNext} returns 0, indicating that the target key \lstinline{k} is in the current node. The \lstinline{traverse} function returns an integer flag that is 1 when we reach a leaf node and 0 when we find \lstinline{k} in an existing node; the behavior of operations that call \lstinline{traverse} can vary depending on this flag. For instance, an \lstinline{insert} operation may create a new node when the flag is 1 and modify an existing node when the flag is 0, while a \lstinline{lookup} operation may fail when the flag is 1 and return the value in the current node when the flag is 0.

%When \lstinline{traverse} arrives at a new node, it acquires the lock for that node and then releases the lock for the current node, according to the lock-coupling pattern---this ensures that the link between the two nodes is not removed or rearranged while traversing it. To utilize the template methodology for concurrent data structure implementations, it is crucial to keep track of the locks acquired for each node during the traversal. 

\subsubsection{Lock-coupling Proof}
\label{traverse_proof_lock}
%\wm{Does this organization work, or would it be better to prove each template as we introduce it?}

The logically atomic specification for the lock-coupling template's \lstinline{traverse} function is shown in Figure \ref{fig:traverse_lock}. \wm{Note that this isn't the same as give-up, and that reflects the original paper. It's the cssOp/insert function that has the same spec in both.}
%\than{Try to avoid using specific name of $\mathrm{tree\_rep}$ for public condition, I suggested to use $\mathrm{Node}$ for generic purpose.} 

%maybe inline this instead of making it a figure?
\begin{figure}[ht]
	\centering
	\begin{mathpar}
		% spec of inRange
		{\color{blue}
			\forall \  m. \left\langle \texttt{pn} \mapsto (\texttt{p, n}) \ \ast \ 
			\nodeboxrep(\texttt{n})  \ \ast \ \mathsf{R}(\texttt{n}) \ \big| \ \treerep\ m \
			\right\rangle
		}
		\\ 
		\texttt{traverse(pn, k)} 
		\\
		{\color{blue}
			\left\langle \mathit{res}. \ \exists \  \texttt{n'}.
			\begin{array}{c} \texttt{pn} \mapsto (\texttt{p, n}) \ \ast 
				\ (\mathit{res} \leftrightarrow (\texttt{pn->n'->t} = \texttt{NULL}))  \ \ast \ \nodeboxrep(\texttt{pn->n'}) \\  
				\ast \ \mathsf{R}(\texttt{pn->n'})\ \ast \ (\texttt{k} \in \mathsf{range}(\texttt{n'}))
			\end{array}
			\ \Bigg| \ \treerep\ m \
			\right\rangle
		}
	\end{mathpar}
	\caption{Specification of \texttt{traverse} for the lock-coupling template}
	\label{fig:traverse_lock}
\end{figure}

The definitions of $\nodeboxrep$ and $\treerep$ may vary depending on the data structure, but fundamentally, $\nodeboxrep$ holds the resources owned by each client thread, while $\treerep$ holds the abstract representation of the data structure, treated as an atomically accessed shared resource. In particular, holding $\nodeboxrep(\texttt{pn->n})$ should allow us to acquire the lock on node \texttt{pn->n}, which in turn gives us access to the contents of the node. Formally, we write
\[\nodeboxrep(\texttt{pn->n}) \triangleq\ \texttt{pn->n->lock} \lockvar \mathsf{R}(\texttt{pn->n})\]
where the \emph{lock invariant assertion} $\ell \lockvar \mathsf{R}$ expresses that the lock $\ell$ protects resources $\mathsf{R}$. In this case, $\mathsf{R}$ contains the contents of the node (i.e., the \lstinline{node} struct contained inside the \lstinline{node_t} struct of \lstinline{pn->n}).

Recall that in the lock-coupling pattern, each thread always holds at least one lock while traversing the data structure, ensuring that other threads cannot interfere with the traversal or invalidate the ongoing search. Consequently, before calling the \texttt{traverse} function, a thread must acquire the lock for the current node $\texttt{pn->n}$ and obtain the resources $\mathsf{R}(\texttt{pn->n})$ guarded by the lock. These resources may depend on the specific data structure, but always include a piece of \emph{ghost state} describing the current state of the node (its key, value, and key range) shared between the invariant $\mathsf{R}$ and the abstract state $\treerep$, ensuring that the lock and the abstract state agree on the contents of the node. \wm{Should we replace this with a concrete definition of the invariant? e.g. $R = ghost\_node(k, v, range) * ...$} 

%As mentioned earlier, we can define a piece of ghost state, $\texttt{ghost\_node t}$, connecting the node in memory to the public abstract state of the data structure. Specifically, we can have one half of the ghost state contained in the resource $\texttt{R(pn->n)}$, and the other half in the abstract state $\texttt{Node t}$. When proving the atomic triple above, at the linearization point where we access $\texttt{Node}$, we combine both halves of the ghost state, update them to reflect the new state of the concrete data structure, and then fulfill the atomic postcondition with one half of the ghost state, returning the other half to the lock invariant.

In the specification, the local precondition includes both the node handle $\nodeboxrep(\texttt{pn->n})$ and the contents $\mathsf{R}(\texttt{pn->n})$. The output of \lstinline{traverse} is a new node \lstinline{n'} in the data structure such that the key \texttt{k} falls within the range of \lstinline{n'}. The local postcondition then includes the handle of the new node $\nodeboxrep(\texttt{pn->n'})$ \wm{This looks weird: \lstinline{pn} doesn't have an \lstinline{n'} field}, its contents $\mathsf{R}(\texttt{pn->n'})$, and a Boolean variable $\mathit{res}$ indicating whether \texttt{pn->n'->t} is \texttt{NULL} or not \wm{Indicate the relationship between \lstinline{res} and the \lstinline{flag} return value}. The key to the correctness of the \texttt{traverse} function the loop invariant for the top-level loop, which expresses that in each iteration, \lstinline{traverse} holds the lock on a node that has \lstinline{k} in its range:
\begin{mathpar}\mathsf{traverse\_inv}(\texttt{pn}) \triangleq\ \exists \ \texttt{n'}.\ \texttt{k} \in \mathsf{range}(\texttt{n'})\ \land \ \texttt{pn} \mapsto (\texttt{p, n}) \ast \nodeboxrep(\texttt{n'})  \ \ast \  \mathsf{R}(\texttt{n'})
\end{mathpar}\wm{Where does \lstinline{range} come from here?}

\begin{figure}[h]
	$\color{blue}
	\forall \  m. \left\langle \texttt{pn} \mapsto (\texttt{p, n}) \ \ast \ 
	\nodeboxrep(\texttt{n})  \ \ast \ \mathsf{R}(\texttt{n}) \ \big| \ \treerep\ m \
	\right\rangle$
	\begin{lstlisting}[language = C, style=myStyle, mathescape=true]
		int traverse(pn *pn, int k){
			int flag = 1; 			$\left\{\begin{array}{l}  ...		\end{array}\right\} \Rrightarrow \left\{\begin{array}{l} \mathsf{traverse\_inv} \end{array}\right\}$
			for( ; ; ){ 			$\left\{\begin{array}{l} \mathsf{traverse\_inv} \end{array}\right\} \triangleq \left\{\begin{array}{l} ... \end{array}\right\}$
				pn->p = pn->n;
				if (pn->p->t == NULL)
				break;
				else{
					int b = findNext(pn, k);
					if (b == 0){
						flag = 0;
						break;
					}
					else{
						acquire(pn->n->lock);
						release(pn->p->lock);
					}
				}
			}
			return flag;
	}  \end{lstlisting}
	$\color{blue}
	\left\langle \mathit{res}. \ \exists \  \texttt{n'}.
	\begin{array}{c} \texttt{pn} \mapsto (\texttt{p, n'}) \ \ast 
		\ (\mathit{res} \leftrightarrow (\texttt{n'->t} = \texttt{NULL}))  \ \ast \ \nodeboxrep(\texttt{n'}) \ \ast \
		\\ \mathsf{R}(\texttt{n'})\ \ast \ (\texttt{k} \in \mathsf{range}(\texttt{n'}))
	\end{array}
	\ \Bigg| \ \treerep\ m \
	\right\rangle$
	\caption{The \texttt{traverse} function in lock-coupling template annotated with separation logic specification}
\end{figure}

Given this invariant, the proof proceeds as follows. \wm{Should we consider giving annotated code after all?} We begin by checking whether the current node is null (line 5 of Figure~\ref{traverse_lock_b}); if it is, we have found the leaf where \lstinline{k} belongs, and can prove the postcondition with $\mathit{res} = \texttt{true}$. Otherwise, we use \lstinline{findNext} to find a new node \lstinline{n'} to visit (line 8), which is stored in \lstinline{pn->n}. If \lstinline{findNext} returns 0, we have found a node containing \lstinline{k}, and can prove the postcondition with $\mathit{res} = \mathtt{false}$. Otherwise, we acquire \lstinline{pn->n->lock}, gaining access to the resources $\mathsf{R}(\texttt{pn->n})$, and then release the lock of the current node \texttt{pn->p} and return its resources. %It is important to note that \texttt{p} point to the same memory address as \texttt{n} (line 4 in Figure \ref{traverse_lock_b}).
By acquiring the lock for the next node \texttt{n} before releasing the lock for the current node \texttt{p}, we ensure that the connection between the two nodes remains intact and unaltered while we traverse it, and re-establish $\mathsf{traverse\_inv}$ for the new values in \lstinline{pn}. 
%The proof concludes by verifying that the \lstinline{traverse} function fulfills the post-condition of the specification mentioned earlier.


\subsection{Give-Up Template}
\label{give-up-algo}

We next consider the give-up template, which uses an \emph{optimistic concurrency control} approach, acquiring fewer locks at the cost of sometimes having to recover from synchronization errors. Unlike the lock-coupling template, which maintains locks during traversal between nodes, the give-up template only acquires a lock just before operating on a node, and holds at most one lock at any time. This means that a conflicting operation may invalidate our traversal, for instance by moving the next node to another part of the data structure before we acquire its lock. To guard against this, the give-up template maintains a \emph{range} field on each node indicating the range of keys that should be stored in this node and its successors, and \lstinline{traverse} must check the range field at each node to ensure that it is still on the right path. If a check fails, we give up and start the traversal over from the root node. The give-up template performs well in scenarios where operations generally do not conflict, either because they are mostly to independent parts of the data structure or because they mostly do not delete or relocate nodes.

\begin{figure}[!ht]
	\begin{subfigure}[t]{0.45\textwidth}
		\lstinputlisting[language=caml, style=myStyle]{giveup_traverse.ml} 
		\caption{The \lstinline{traverse} method of the give-up template algorithm written in an ML-like language}
		\label{traverse_giveup_a}	
	\end{subfigure}\qquad
	\begin{subfigure}[t]{0.48\textwidth}
		\lstinputlisting[language=C, style=myStyle]{giveup_traverse.c} 
		\caption{The \lstinline{traverse} method of the give-up template algorithm written in C}
		\label{traverse_giveup_b}
	\end{subfigure}
	\caption{The \lstinline{traverse} method of the give-up template algorithms}
	\label{traverse_giveup}
\end{figure}

Figure \ref{traverse_giveup_a} depicts the give-up template algorithm as originally presented. In addition to \lstinline{findNext}, the \lstinline{traverse} function uses a helper function called \lstinline{inRange}, which determines whether the key value $\texttt{k}$ falls within the range of keys held in node $\texttt{n}$ and its successors. If \lstinline{k} is outside the node's range (e.g. because the node has been relocated), the search is restarted from the root node \lstinline{r}. As in the previous section, we implement this in C with a loop: in each iteration, we acquire the lock on the current node, check that \lstinline{k} is in range, and then use \lstinline{findNext} as above, releasing the lock before we move to the next node. If the \lstinline{inRange} call fails, we release our current lock and return to the root node by setting the current node to the root pointer \lstinline{p} (lines 21-22 in Figure \ref{traverse_giveup_b}).

The \lstinline{inRange} function raises an interesting question about the template approach: is \lstinline{inRange} part of the give-up template, or the underlying data structure? Some data structures may already track the range of keys expected in the current node, and so might define \lstinline{inRange} even in sequential implementations. However, in most sequential settings the key ranges can be computed from the data structure (e.g., in a binary search tree, the left subtree of a node with key \lstinline{k} holds keys less than \lstinline{k}), and there is no reason to explicitly store a node's range in the node itself. The give-up template of Krishna et al.~implicitly assumes that the underlying data structure supports \lstinline{inRange}; we prefer to consider \lstinline{inRange} part of the template, so that the template can be applied to as many target data structures as possible without modifying them. Accordingly, in this template we add two new fields, \lstinline{min} and \lstinline{max}, to the type \lstinline{node_t} in our C implementation:
\begin{lstlisting}[language = C, backgroundcolor=\color{white}, basicstyle=\ttfamily\footnotesize]
	typedef struct node_t {node *t; lock_t *lock; int min; int max;} node_t;
\end{lstlisting}
These fields store lower and upper bounds on the keys reachable from the current node. %In the context of binary search trees, each node is labeled with a range that is associated with a lower and upper bound on the keys. This begins with $(\texttt{min}, \texttt{max}) = (-\infty, +\infty)$ at the root node and is propagated to the empty leaf nodes. If the root node (which also serves as the parent of a node) has a key of $42$, the left leaf node's range would be $(\texttt{min}, \texttt{max}) = (-\infty, 42)$, and the right leaf node's range would be $(\texttt{min}, \texttt{max}) = (42, +\infty)$.
We can then define \lstinline{inRange} as a helper function in the template, rather than requiring data structures to provide it. \wm{This is the first but not the last implicit assumption in the templates; can we say something more general?}

\subsubsection{Give-up Template}
\label{traverse_proof_giveup}

The atomic specification for the give-up template's \lstinline{traverse} is shown in Figure \ref{fig:traverse_giveup}.

\begin{figure}[h]
	\centering
	\begin{mathpar}
		% spec of inRange
		{\color{blue}
			\forall \  m. \left\langle
			\begin{array}{c}
				\infp (\texttt{pn->n}) \ \big| \ \treerep\ m
			\end{array}
			\right\rangle
		}
		\\ 
		\texttt{traverse(pn, k)} 
		\\
		{\color{blue}
			\left\langle \mathit{res}. \ \exists \ \texttt{n'}.
			\begin{array}{c}
				(\mathit{res} \leftrightarrow (\texttt{pn->n'->t} = \texttt{NULL}))  \ \ast \ \infp(\texttt{pn->n'}) 
				\\ 
				\ast \ \mathsf{R}(\texttt{pn->n'}) \ \ast \ (\texttt{k} \in \mathsf{range}(\texttt{n'}))
			\end{array}
			\ \Bigg| \ \treerep\ m \
			\right\rangle
		}
	\end{mathpar}
	\caption{Specification of \texttt{traverse} for the give-up template}
	\label{fig:traverse_giveup}
\end{figure}

The give-up template's \texttt{traverse} specification is simpler than that of the lock-coupling template. The local precondition include any locks, and consists only of $\infp(\texttt{pn->n})$, a footprint predicate asserting that node \texttt{n} is included in the search structure's abstract state $m$. As before, the \texttt{traverse} function will navigate the structure and return a node \texttt{n'} whose range includes \texttt{k}, as well as acquiring \lstinline{n'}'s lock and returning its contents $\mathsf{R}(\texttt{pn->n'})$. Also as before, the Boolean $\mathit{res}$ indicates whether \texttt{pn->n'->t} is \texttt{NULL} or not.

%\wm{We really need to explain why we have this difference, or get rid of it.} In contrast to the lock-coupling style, where each lock is associated with a lock-invariant, in the give-up template we treat locks more abstractly. 
For each node, we track whether its lock is held or not, and the abstract state $\treerep$ holds the contents of all nodes whose locks are not currently held. Formally, we write \[\mathsf{inv\_for\_lock} \ \ell \ \mathsf{R} \triangleq \exists b. \ \ell \mapsto b \ \ast \ \mathsf{if}\ b \ \mathsf{then}\ \mathsf{emp}\ \mathsf{else}\ \mathsf{R}\]\wm{Consider using mathsf for logic and reserving texttt for C code.}
%where a lock at location $\ell$ safeguards resources denoted by \texttt{R}. When the lock is held, meaning the node is locked ($\ell \mapsto \texttt{true}$), threads can remove resources \texttt{R} from $\treerep$. On the other hand, when the lock is not held ($\ell \mapsto \texttt{false}$), resources \texttt{R} are required to be part of the invariant.
and $\treerep$ contains an $\mathsf{inv\_for\_lock}$ assertion for each node in the data structure. As before, $\mathsf{R}$ contains the concrete contents of each node, but also includes the \lstinline{min} and \lstinline{max} fields that we use to implement the \lstinline{inRange} check.

Next, we define the loop invariant for the give-up template's \texttt{traverse} function:
\begin{mathpar} \mathsf{traverse\_inv}(\texttt{pn}) \triangleq \ \exists \ \texttt{n'}.\ \infp (\texttt{pn->n}) \ast \infp (\texttt{pn->n'})   
\end{mathpar}
With this invariant in hand, the proof of \lstinline{traverse} proceeds as follows. We start with the $\infp (\texttt{pn->n})$ predicate from the local precondition. After acquiring the lock of the node $\texttt{pn->n}$ (line 5 in Figure \ref{traverse_giveup_b}), we obtain the resource $\mathsf{R}(\texttt{pn->n})$, which allows us to perform the \lstinline{inRange} check on line 7. If the check fails (lines 20-23), we immediately release the lock and start over from the beginning. Otherwise, we proceed as before: if the current node's contents are \texttt{NULL}, we have found the empty leaf where \lstinline{k} belongs (and can satisfy the postcondition); if \lstinline{findNext} returns 0, we have found the node containing \lstinline{k} (and can satisfy the postcondition); otherwise, we release our lock and re-establish $\mathsf{traverse\_inv}$ for the new node indicated by \lstinline{findNext}. In this case, we do not hold the lock on the new node, but only the $\infp$ assertion indicating that the new node is in the data structure. % and add the additional predicate $\texttt{k} \in \texttt{range(n)}$ in the \texttt{then} of \texttt{inRange}. Similar to the proof of the lock-coupling template's \texttt{traverse}, the traversal stops when it reaches the base case, which occurs when the current node is \lstinline{NULL} (line 8 in Figure \ref{traverse_giveup_b}). At this point, we can prove the post-condition using the specification, which indicates that $\texttt{k} \in \texttt{range(n')} \ast \texttt{pn->n'->t} = \texttt{NULL}$.

%If \lstinline{findNext} cannot find a subsequent node with the key value $\texttt{k}$ within its set of key values, the function terminates. Otherwise, it successfully detects the next node (for example, \texttt{n'}) to visit, giving a predicate that asserts \texttt{n'} is in the footprint of the structure, $\infp(\texttt{pn->n})$. After releasing the lock of the current node \texttt{p} (since \texttt{p} and \texttt{n} point to the same memory address - line 6 in Figure \ref{traverse_giveup_b}), we can prove that it satisfies the loop invariant $\texttt{traverse\_inv(pn)}$ and complete this branch of the proof. In the \texttt{else} branch of the call to \texttt{inRange}, since \texttt{k} is not in the range of the current node \texttt{p}, the function gives up and relinquishes the lock on \texttt{p}, then goes back to the root of the data structure to retry.






\section{Verified Data Structures}
In this section, we demonstrate how to instantiate the templates with specific data structures, giving us verified concurrent data structures in C. The target specifications for our search structure operations are shown below: each operation should atomically have its effect on the data structure, modifying it or returning information as appropriate\footnote{Krishna et al.~\cite{templates} combine these specifications into a single function parameterized by the choice of operation; however, clients will still ultimately want to call \lstinline{insert}, \lstinline{lookup}, or \lstinline{delete} functions.}.

\begin{mathpar}
	{\color{blue}
		m.\left\langle 
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ m
		\right\rangle
	}
	\ \texttt{insert(p, k, v)}\ 
	{\color{blue}
		\left\langle 
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ (m[\texttt{k} \mapsto \texttt{v}])
		\right\rangle
	}
\\
	{\color{blue}
		m.\left\langle 
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ m
		\right\rangle
	}
	\ \texttt{lookup(p, k)}\ 
	{\color{blue}
		\left\langle \texttt{v}. \ \
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ m \land m(\texttt{k}) = \texttt{v}
		\right\rangle
	}
\\
	{\color{blue}
		m.\left\langle 
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ m
		\right\rangle
	}
	\ \texttt{delete(p, k)}\ 
	{\color{blue}
		\left\langle 
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ (m[\texttt{k} \mapsto \_ ])
		\right\rangle
	}
\end{mathpar}
The intention of the template approach is that we should be able to derive implementations from these operations from \lstinline{traverse} instantiated with an appropriate \lstinline{findNext} function, and prove them correct using the \lstinline{traverse} specs of the previous section, without any further reasoning about specific concurrency patterns.

Our target data structure is a binary search tree (BST) implemented in C, a data structure that was already defined and verified as a demonstration of VST's concurrency capabilities. We factor out \lstinline{findNext} and \lstinline{traverse} functions as described above, and verify lock-coupling and give-up versions of the BST using the templates. We discuss the verification of \texttt{insert} for each template in detail; the \texttt{lookup} proofs follow similar reasoning. As for \texttt{delete}, there is a mismatch between the template approach and BST deletion, which we discuss in Section \ref{internal_reorganize}. The complete proofs in VST can be found online at \href{https://github.com/PrincetonUniversity/DeepSpecDB/tree/master/concurrency/templates}{\color{blue}{https://github.com/PrincetonUniversity/DeepSpecDB/tree/master/concurrency/templates}}; we discuss the overall development in Section \ref{proof_mech}.

\wm{Should we have a separate section where we introduce findNext (and maybe insertOp) before we get into specific templates?}

We instantiate the template with the binary search tree by defining and verifying the helper functions \texttt{findNext} (used in \lstinline{traverse}) and \texttt{insertOp} (used in \texttt{insert}). Their implementations are strictly sequential, their specifications are ordinary non-atomic Hoare triples, and their proofs do not require any concurrency reasoning.

\begin{figure}[h]
	\centering
	%\wm{I think this should be \lstinline{pn->n->t} $\mapsto$ \lstinline{(k',v', l, r)}, but I'm not sure.}
	\begin{mathpar}
		{\color{blue}
			\left\{ 
			\begin{array}{c}
				\texttt{pn->n->t}\mapsto \texttt{(k', v', l, r)} 
			\end{array}
			\right\}
		}
		\\ 
		\texttt{findNext(pn, k)} 
		\\
		{\color{blue}
			\left\{\mathit{res}. \ \exists \  \texttt{n'.}
			\begin{array}{c}
				\texttt{pn->n->t}\mapsto \texttt{(k', v', l, r)}  \\\  
				\ast \ (\mathsf{if}\ \mathit{res}\ \mathsf{then}\ (\texttt{l} = \texttt{n'} \land \texttt{k} < \texttt{k'}) \lor (\texttt{r} = \texttt{n'} \land \texttt{k} > \texttt{k'})\ \mathsf{else}\ (\texttt{n} = \texttt{n'} \land \texttt{k} = \texttt{k'}))
			\end{array}
			\right\}
		}
	\end{mathpar}
	\caption{Specification of \texttt{findNext} for the binary search tree (all templates)} %\wm{Shouldn't pn have two fields, p and n?}
	\label{fig:findNext_lock}
\end{figure}


\begin{figure}[h]
	\begin{subfigure}{\textwidth}
	\centering
	\begin{mathpar}
		{\color{blue}
			\left\{ 
			\begin{array}{c}
				\ \texttt{pn->n->t}  
			\end{array}
			\right\}
		}
		\\ 
		\texttt{insertOp(pn, k, v)} 
		\\
		{\color{blue}
			\left\{\exists \  \texttt{t' l r lk1 lk2}.
			\begin{array}{c}
				\ \texttt{pn->n->t'} \ \ast \ \texttt{t'}\mapsto \texttt{(k, v, l, r)} \ \ast \ \\ 
				\ \texttt{l} \mapsto \texttt{(NULL, lk1)}\  \ast \ \texttt{r} \mapsto \texttt{(NULL, lk2)}
			\end{array}
			\right\}
		}
		\end{mathpar}
		\caption{Specification of \texttt{insertOp} for the lock-coupling template}
			\label{fig:insertOp_lock}
	\end{subfigure}
	%insertOp for give-up of give-up
	\begin{subfigure}{\textwidth}
		\begin{mathpar}
	{\color{blue}
		\left\{ 
		\begin{array}{c}
			\texttt{pn}\mapsto\texttt{n} \ \ast \ \texttt{n}\mapsto\texttt{t} \  \ast \ \texttt{n}\mapsto\texttt{min} \ \ast \ \texttt{n}\mapsto\texttt{max}
		\end{array}
		\right\}
	}
	\\
	\texttt{insertOp(pn, k, v)}
	\\
	{\color{blue}
		\left\{\exists \ \texttt{t' l r lk1 lk2}. 
		\begin{array}{c}
			\ \texttt{pn}\mapsto\texttt{n} \ \ast \ \texttt{n}\mapsto\texttt{t'} \ \ast \ \texttt{t'}\mapsto \texttt{(k, v, l, r)} \\ 
			\ \ast \ \texttt{l} \mapsto \texttt{(NULL, lk1, (min, k))} \ \ast \ \texttt{r} \mapsto \texttt{(NULL, lk2, (k, max))}
		\end{array}
		\right\}
	}
	\end{mathpar}
	\caption{Specification of \texttt{insertOp} for the give-up template}
	\label{fig:insertOp_giveup}
\end{subfigure}
	\caption{Specification of \texttt{insertOp} for the lock-coupling template}
	\label{fig:insertOp}
\end{figure}

\wm{Should we recap the definition of the \lstinline{node} struct here?} The precondition of \texttt{findNext} (Figure \ref*{fig:findNext_lock}) states that the input has a non-null \texttt{t} field pointing to a \texttt{node} struct with the current node's key \texttt{k'}, value \texttt{v'}, and pointers to the left \texttt{l} and right \texttt{r} child nodes. The postcondition describes three possible outcomes: either the provided key \texttt{k} is less than the current node's key \texttt{k'}, and the next node \lstinline{n'} is the left child \lstinline{l}; \lstinline{k} is greater than \lstinline{k'} and \lstinline{n'} is the right child \lstinline{r}; or \lstinline{k} is exactly \lstinline{k'} and \lstinline{n'} is the original node \lstinline{n}, in which case the return value is 0.

The \texttt{insertOp} specification (Figure \ref{fig:insertOp_lock}) takes as input a node whose \lstinline{t} field is \lstinline{NULL}, i.e., an empty leaf node. It inserts a new node with the specified key \texttt{k} and value \texttt{v} at that leaf, complete with two new empty child nodes with corresponding locks, \texttt{(NULL, lk1)} and \texttt{(NULL, lk2)}, which are pointed to by the \texttt{l} and \texttt{r} of the current node.  

\than{Talking about different of \texttt{insertOp} specs here.}


As previously mentioned, the \texttt{insertOp} specification (Figure \ref{fig:insertOp_giveup}) is slightly different from the lock-coupling version, to account for the added \lstinline{min} and \lstinline{max} fields. In a BST, if the current node's range is \lstinline{(min, max)} and its key is \lstinline{k}, its left child will have range \texttt{(min, k)} and its right child will have range \texttt{(k, max)}. Otherwise, \lstinline{insertOp} behaves identically, storing \lstinline{k} and \lstinline{v} in the current node and creating two empty child nodes.


\subsection{Lock-coupling BST}
\begin{figure}[h]
	\begin{subfigure}[t]{0.48\textwidth}
	\lstinputlisting[language=C, style=myStyle, escapechar=|]{lock_insert.c} 
	\caption{The \lstinline{insert} method of the lock-coupling template algorithm}
	\label{insert_lock}	
	\end{subfigure}\qquad
    \begin{subfigure}[t]{0.48\textwidth}
    \lstinputlisting[language=C, style=myStyle]{giveup_insert.c} 
    \caption{The \lstinline{insert} method of the give-up template algorithm}
    \label{insert_giveup}
    \end{subfigure} 
\caption{The \lstinline{insert} method of the lock-coupling and give-up template algorithms}
\label{insert_lock_giveup} 
\end{figure}

Figure \ref{insert_lock} shows the implementation of \lstinline{insert} for the lock-coupling BST. \wm{Actually, is this \lstinline{insert} function part of the template? If so, should we discuss it in section 3?} It makes use of the \texttt{traverse} function of Section \ref{lock-coupling-algo} to find the node at which to insert the key \lstinline{k}. If \texttt{traverse} returns 0, it has reached a node containing key \texttt{k}, and we only have to change the node's value to the target \texttt{value} (lines 5-6 in Figure \ref{insert_lock}). Otherwise, \texttt{traverse} has reached an empty leaf that can hold key \texttt{k}, so it calls the data-structure-specific \texttt{insertOp} function to allocate a new node with key \texttt{k} and value \texttt{v} (line 9 in Figure \ref{insert_lock}).



The atomic specification for \texttt{insert} method is
\begin{mathpar}
	{\color{blue}
		m.\left\langle 
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ m
		\right\rangle
	}
	\ \texttt{insert(p, k, v)}\ 
	{\color{blue}
		\left\langle 
		\nodeboxrep\ \texttt{p} \ \big | \ \treerep\ (m[\texttt{k} \mapsto \texttt{v}])
		\right\rangle
	}
\end{mathpar}
\wm{Consider skipping this paragraph if we need space.} Similar to the \texttt{traverse} specification, the \texttt{insert} function's specification is composed of two components: local and public pre- and postconditions. The local pre- and postconditions, containing $\nodeboxrep \ \texttt{p}$, describe the binary search tree's concrete state with the root node $\texttt{p}$, which points to the node's lock and lock invariant assertion. On the other hand, the public pre- and postconditions are represented by the predicate $\treerep \ m$, illustrating the binary search tree's abstract state as a collection of ghost states, with each state providing information about an individual node in the tree. Here, $m$ and $m[\texttt{k} \mapsto \texttt{v}]$ denote the tree's abstract states before and after the function's execution, respectively. 

The proof for \texttt{insert} begins with the precondition $\nodeboxrep \ \texttt{p}$. We set \texttt{pn->n} to point to the root node \texttt{*p} (line 3 in Figure \ref{insert_lock}). After the lock for the root node is acquired (line 4 in Figure \ref{insert_lock}), the thread acquires the contents of the root node, $\mathsf{R}(\texttt{pn->n})$. We can then satisfy the precondition of the lock-coupling \lstinline{traverse} function from Section \ref{traverse_proof_lock} \wm{Maybe we should show the spec again here}, allowing us to call \lstinline{traverse} and obtain its postcondition.

In the $\mathsf{then}$ branch, when \texttt{traverse} finds a node with key \lstinline{k}, %resulting in $\texttt{res} = \texttt{false}$, 
we know that $\texttt{pn->n'->t} \neq \texttt{NULL}$, i.e., the key to be inserted already exists in the tree. In this scenario, we update the node's value while maintaining the rest of the tree structure (line 6 in Figure \ref{insert_lock}). Otherwise, when \texttt{traverse} reaches a leaf and produces $\mathit{res} = \texttt{true}$, we know that $\texttt{pn->n'->t} = \texttt{NULL}$ (at line 9 in Figure \ref{insert_lock}). We can then call the \texttt{insertOp} specification, adding the new key-value pair to the tree. In either case, before we release the node's lock, we must show that we have altered the tree from its current abstract state $m$ to $m[\texttt{k} \mapsto \texttt{v}]$, thereby satisfying the public postcondition of \lstinline{insert}. We do this by demonstrating that the in-memory tree update corresponds to setting \lstinline{k} to \lstinline{v} in the abstract key-value map of the tree. 
We can then release the lock (line 11 in Figure \ref{insert_lock}) return the node's contents to the shared state. %Subsequently, we demonstrate the postcondition of the \texttt{insert} function to complete the proof.
\wm{Do we ever define $\treerep$?}

\subsection{Give-up BST}

The give-up version of the \texttt{insert} method (see Figure \ref{insert_giveup}) is almost identical to the lock-coupling version. The one difference is that it does not require acquiring a lock before calling its \texttt{traverse} function. 

The give-up BST uses the same definition and specification of \texttt{findNext}, while introducing an extra helper function called \texttt{inRange} \wm{If \lstinline{inRange} is part of the template, I think we should discuss it in the previous section}. The \texttt{insertOp} function is slightly different from that of the lock-coupling template, as each \lstinline{node_t} struct has two additional fields, \texttt{min} and \texttt{max}, to implement \lstinline{inRange}, as described in Section \ref{give-up-algo}.

\begin{figure}[h]
	\centering
	\begin{mathpar}
		% inRange for give-up
		{\color{blue}
			\left\{ 
			\begin{array}{c}
				\texttt{pn->n}\mapsto\texttt{(t, lock, min, max)} 
			\end{array}
			\right\}
		}
		\\ 
		\texttt{inRange(pn, k)} 
		\\
		{\color{blue}
			\left\{\mathit{res.} \
			\begin{array}{c}
				\ \texttt{pn->n}\mapsto\texttt{(t, lock, min, max)} \  \ast  \ 
				\\(\mathsf{if}\ \mathit{res}\ \mathsf{then}\ (\texttt{min} < \texttt{k} < \texttt{max})\ \mathsf{else}\ (\texttt{k} \leq \texttt{min} \lor \texttt{k} \geq \texttt{max}))
			\end{array}
			\right\}
		}
	\end{mathpar}
	\caption{Specifications of \texttt{inRange} and \texttt{insertOp} for the give-up template}
	\label{fig:inRange_giveup}
\end{figure}

The \texttt{inRange} function (Figure \ref{fig:inRange_giveup}) simply computes whether the input key \lstinline{k} is in the range \texttt{(min, max)} associated with the node \texttt{n}, and returns 0 or 1 accordingly.


%The \texttt{insert} specification for the give-up template is identical to that of the lock-coupling template, up to changes in the definitions of $\nodeboxrep\ \texttt{p}$ and $\treerep \ \texttt{m}$. %Essentially, the \texttt{insert} function's specification comprises two main components: local and public preconditions and postconditions, as previously mentioned. Moreover, we must demonstrate that it is possible to atomically update the tree's abstract state from an unknown \texttt{m} to $\texttt{m[k} \mapsto \texttt{v])}$.
%The local preconditions and postconditions, containing $\nodeboxrep \ \texttt{p}$, depict the binary search tree's concrete state, where the root node $\texttt{p}$ points to the node's lock and footprint predicate, signifying that the root node is located within the search structure's footprint. In contrast, the public preconditions and postconditions are denoted by the predicate  $\treerep \ \texttt{m}$, which is identical to the public predicates of the \texttt{traverse} function in the give-up template. 

%The proof for the \texttt{insert} operation begins with the preconditions $\nodeboxrep \ \texttt{p}$ and $\treerep \ \texttt{m}$. We assign \texttt{pn->n} to point to the same memory address as \texttt{*p} (line 3 in Figure \ref{insert_giveup}). In Section \ref{traverse_proof_giveup}, we discuss providing the identical preconditions for the \texttt{traverse} function, which encompasses the local precondition $\infp\texttt{(pn->n)}$ and the public precondition $\treerep\ \texttt{m}$. Subsequently, we apply the \texttt{traverse} specification from Section \ref{traverse_proof_giveup}.

%Analogous to the lock-coupling template's \texttt{insert} operation, there are two possible branches representing the outcome following the execution of \texttt{traverse}. Once we demonstrate the ability to atomically update the tree's abstract state from $\treerep \ \texttt{m}$ to $\treerep\ \texttt{(m[k} \mapsto \texttt{v])}$, we proceed by releasing the node \texttt{n} and returning it to the shared state, thereby finalizing the proof.

The proof of the \lstinline{insert} function is similar to that of the previous function: the only difference is that the give-up version of \lstinline{insert} does not acquire a lock before calling \lstinline{traverse}, reflecting the difference in the locking patterns and the preconditions of \lstinline{traverse} between the two templates.

\subsection{Templates vs. Internal Reorganization}
\label{internal_reorganize}
The third BST operation, \lstinline{delete}, presents problems in applying the template approach. The operations we have seen thus far can be factored into a data-structure-agnostic concurrent step (\lstinline{traverse}) and a concurrency-unaware data structure step (\lstinline{insert} or \lstinline{lookup}). When removing a node from a BST, on the other hand, we usually restructure the tree with a \lstinline{pushdown_left} operation, %include figure?
rotating three-node sections of the tree until the node to be deleted is at a leaf. This operation is simultaneously concurrency-aware (we must lock the nodes involved to avoid race conditions) and data-structure-specific (we need to know precisely which nodes to target and how to rearrange them). This contrasts with linked-list deletion, which only involves the target node and its immediate neighbors. In practice, Krishna et al.'s proofs for tree structures~\cite{templates} either do not include deletion at all, or use a very lightweight form of deletion in which nodes are marked as ``deleted'' but are never actually removed from the data structure.

We believe this represents a fundamental limitation in the template approach. Operations in the style of \lstinline{pushdown_left} are ubiquitous in tree structures (e.g., the rebalancing operations of AVL and red-black trees), and always weave together synchronization and restructuring in a way that cannot easily be decomposed. This is a serious impediment to the goal of verifying concurrency control separately from the data structure: even if we have a verified template and a verified single-threaded tree, we still need to verify a complex data-structure-specific concurrent function. %in fact, usually the most complicated part!
%what's the conclusion here? can we see a way through?

\section{Proof Mechanization}
\label{proof_mech}
All the proofs described above have been mechanized in VST, using its extensions for logical atomicity~\cite{iris-vst-arxiv}. Statistics on the verification effort are shown in Table~\ref{table_coq}

\begin{table}[h]
	\begin{center}
		\begin{tabular}{l | c || l | c } 
			\hline
			\textbf{Lock-coupling template} & \textbf{Line of proofs} & \textbf{Give-up  template} & \textbf{Line of proofs} \\
			\hline
			Template specfications & 190 & Template specfications & 138 \\
			\texttt{findNext} proof 	& 27  & \texttt{findNext} proof & 27 \\
			\texttt{insertOp} proof 	& 32  & \texttt{insertOp} proof & 31 \\
			& & \texttt{inRange} proof & 30 \\
			\texttt{traverse} proof	& 360  & \texttt{traverse} proof & 336 \\ 
			\texttt{insert} proof 	   		& 450  & \texttt{insert} proof & 284 \\
			\texttt{lookup} proof 	   	& 235  &  \texttt{lookup} proof & 304 \\ 
			\texttt{pushdown\_left} proof 	   	& 282 & & \\	
			\texttt{delete} proof 		& 182	 &   & 	 \\
			supporting proofs    & 	1909	 & supporting proofs 	& 1876 \\
			\hline
			\textbf{Total} & \textbf{3667} & & \textbf{3026}  
		\end{tabular}
		\caption{Size of Coq definitions and proofs, by topic.}
		\label{table_coq}
	\end{center}
\end{table}

%By utilizing VST, we can create programs in standard C, automatically generate abstract syntax trees (ASTs) for them in Coq, and subsequently state and interactively prove specifications for these programs with the support of automated tactics. Table \ref{table_coq} presents a summary of our Coq development. We formalized all previously described proofs in Coq, taking advantage of VST's features for verifying separation logic specifications of C functions. This encompasses supplementary proofs, template specifications (encompassing all helper functions such as \texttt{findNext}, \texttt{insertOp}, and others, in addition to \texttt{traverse}, \texttt{insert}, \texttt{lookup}, and \texttt{delete}), as well as proofs against with lock-coupling and give-up template specifications. 
\wm{Rather than re-stating what we proved, this is the place to discuss the development: e.g., which parts took the most effort and LoC, which parts we expect to be reusable and in what way, how much bigger or smaller the template proofs were than non-template versions, etc.}

The proofs can be found online at

\href{https://github.com/PrincetonUniversity/DeepSpecDB/tree/master/concurrency/templates}{\color{blue}{https://github.com/PrincetonUniversity/DeepSpecDB/tree/master/concurrency/templates}}

\section{Conclusion and Future Work}
Concurrent search structure templates are a promising approach for proving the correctness of concurrency patterns and data structures separately, and then combining them to obtain verified concurrent data structures. We have translated the approach to apply to C programs using VST, with appropriate imperative versions of the key \lstinline{traverse} functions that define the templates, and used it to prove the correctness of an (appropriately refactored) existing concurrent data structure. However, the translation also exposed some ambiguities and limitations in the approach: for instance, the \lstinline{inRange} function of the give-up template must either be assumed to exist in the data structure or incorporated into the template, and the \lstinline{delete} operation of binary search trees does not decompose naturally into a concurrent part and a data-structure-specific part.  %\wm{Do we have an idea of how to fix this?}
The next step is to implement templates as a truly generic framework, with proofs of \lstinline{traverse}, etc. that can be freely combined with verified sequential data structures via a clear interface that defines the functions a data structure must provide and the assumptions the template makes on them.
Ultimately, we hope to use the template approach to verify data structures such as Masstree~\cite{masstree} and Wormhole~\cite{wormhole}, complicated real-world search structures that combine multiple concurrency patterns for maximum performance on multicore architectures.

%%
%% Bibliography
%% 
%% 

\newpage
\bibliography{../sources}

%\appendix

%\section{Styles of lists, enumerations, and descriptions}\label{sec:itemStyles}

%List of different predefined enumeration styles:

\end{document}
